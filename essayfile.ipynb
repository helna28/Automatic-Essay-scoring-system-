{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helna28/Automatic-Essay-scoring-system-/blob/main/essayfile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLXCtPSF5T-q"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDFpB6af5FhR",
        "outputId": "849011e4-9fa3-4517-b2e7-d76f1e683a22"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package 'openjdk-11-jdk' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openjdk-17-jdk is already the newest version (17.0.16+8~us1-0ubuntu1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "openjdk version \"17.0.16\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n",
            "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.12/dist-packages (2.9.4)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.12/dist-packages (0.7.10)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from language-tool-python) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from language-tool-python) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from language-tool-python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from language-tool-python) (0.10.2)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.12/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.2)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->language-tool-python) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->language-tool-python) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "--2025-10-15 08:33:51--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  3.41MB/s    in 3m 42s  \n",
            "\n",
            "2025-10-15 08:37:34 (3.70 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# === Setup Java 17 and Install Required Libraries ===\n",
        "!apt-get remove openjdk-11-jdk -y\n",
        "!apt-get install openjdk-17-jdk -y\n",
        "!update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-17-openjdk-amd64/bin/java 1\n",
        "!update-alternatives --set java /usr/lib/jvm/java-17-openjdk-amd64/bin/java\n",
        "!java -version\n",
        "\n",
        "# === Install Python Packages ===\n",
        "!pip install -U language-tool-python textstat nltk gradio\n",
        "!wget --no-check-certificate https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ekSgjE6XBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50030d6-4f0e-4f4d-c8ee-e28c56c1e7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFhZkt856XDj",
        "outputId": "60d4c668-a4ba-4b2f-f3cd-157ff940c664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'random', 'text']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "sample_text = \"This is random text\"\n",
        "tokens = word_tokenize(sample_text)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVbu9SQ96XGI",
        "outputId": "a85a4818-680f-4ef1-ebcd-ae3a260e0135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# === 1. Imports and Setup ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "import textstat\n",
        "import gradio as gr\n",
        "import language_tool_python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Cjas0Msz6XIV",
        "outputId": "8a8f9977-9855-4b35-92bf-2adee21500c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 essay_id                                          full_text  \\\n",
              "0           0  000d118  Many people have car where they live. The thin...   \n",
              "1           1  000fe60  I am a scientist at NASA that is discussing th...   \n",
              "2           2  001ab80  People always wish they had the same technolog...   \n",
              "3           3  001bdc0  We all heard about Venus, the planet without a...   \n",
              "4           4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...   \n",
              "\n",
              "   score                                       cleaned_text  \n",
              "0      3  Many people have a car where they live. The th...  \n",
              "1      3  I am a scientist at NASA, discussing the \"face...  \n",
              "2      4  People always wish they had the same technolog...  \n",
              "3      4  We all heard about Venus, the planet with almo...  \n",
              "4      3  Dear State Senator,\\n\\nThis is a letter to arg...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e2e28bc-ef90-4a88-abec-c7d1d9495db4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>score</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>000d118</td>\n",
              "      <td>Many people have car where they live. The thin...</td>\n",
              "      <td>3</td>\n",
              "      <td>Many people have a car where they live. The th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000fe60</td>\n",
              "      <td>I am a scientist at NASA that is discussing th...</td>\n",
              "      <td>3</td>\n",
              "      <td>I am a scientist at NASA, discussing the \"face...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>001ab80</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "      <td>4</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>001bdc0</td>\n",
              "      <td>We all heard about Venus, the planet without a...</td>\n",
              "      <td>4</td>\n",
              "      <td>We all heard about Venus, the planet with almo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>002ba53</td>\n",
              "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
              "      <td>3</td>\n",
              "      <td>Dear State Senator,\\n\\nThis is a letter to arg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e2e28bc-ef90-4a88-abec-c7d1d9495db4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e2e28bc-ef90-4a88-abec-c7d1d9495db4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e2e28bc-ef90-4a88-abec-c7d1d9495db4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/essay_llama3_8B_groq (2).csv\").dropna()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdMriy596XLO"
      },
      "outputs": [],
      "source": [
        "# === 2. Load and Preprocess Dataset ===\n",
        "df = pd.read_csv(\"/content/essay_llama3_8B_groq (2).csv\").dropna()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    return text\n",
        "\n",
        "df['cleaned_essay'] = df['cleaned_text'].apply(clean_text)\n",
        "\n",
        "X = df['cleaned_essay']\n",
        "y = df['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_LJORtt6XOV"
      },
      "outputs": [],
      "source": [
        "# === 3. Tokenization and Padding ===\n",
        "max_words = 10000\n",
        "max_len = 300\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_len)\n",
        "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh3INVP86XQ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === 4. Load GloVe Embeddings ===\n",
        "embedding_index = {}\n",
        "with open(\"glove.6B.100d.txt\", encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = coefs\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "word_index = tokenizer.word_index\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFppdzPP6XTZ",
        "outputId": "e4294c8d-b792-4016-a460-85fed8450be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 1.7096 - val_loss: 0.9778\n",
            "Epoch 2/15\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 1.0965 - val_loss: 0.6123\n",
            "Epoch 3/15\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.7420 - val_loss: 0.5651\n",
            "Epoch 4/15\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.6601 - val_loss: 0.6414\n",
            "Epoch 5/15\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.6784 - val_loss: 0.5759\n"
          ]
        }
      ],
      "source": [
        "# === 5. Build and Train LSTM Model ===\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len,\n",
        "              weights=[embedding_matrix], trainable=False),\n",
        "    LSTM(128),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_seq, y_train, epochs=15, batch_size=32,\n",
        "                    validation_split=0.1, callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnk_0Ujw6XWM",
        "outputId": "1a0c5a6f-4b35-4c5d-a76b-63a482f16abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "MSE: 0.5985034108161926\n",
            "QWK: 0.5887916159217434\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_seq)\n",
        "y_pred_rounded = np.clip(np.rint(y_pred), 0, 6)\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"QWK:\", cohen_kappa_score(y_test.astype(int), y_pred_rounded.astype(int), weights='quadratic'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms7QEj_W6XYz"
      },
      "outputs": [],
      "source": [
        "# # === 7. Save Model and Tokenizer ===\n",
        "# model.save(\"/content/drive/MyDrive/aes_lstm_glove_model.keras\")\n",
        "# with open(\"/content/drive/MyDrive/aes_tokenizer_glove.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "651aUfH86XbX"
      },
      "outputs": [],
      "source": [
        "# === 8. Feedback Generation ===\n",
        "def extract_keywords(text, top_n=20):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    X = vectorizer.fit_transform([text])\n",
        "    scores = X.toarray()[0]\n",
        "    indices = np.argsort(scores)[::-1][:top_n]\n",
        "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "    return feature_names[indices]\n",
        "\n",
        "def content_score(essay_text, keywords):\n",
        "    essay_lower = essay_text.lower()\n",
        "    matched_keywords = [word for word in keywords if word in essay_lower]\n",
        "    score = len(matched_keywords) / len(keywords) * 4  # Max 4 points for content\n",
        "    return round(score, 2), matched_keywords\n",
        "\n",
        "def generate_feedback(pred_score, essay_text, content_keywords):\n",
        "    import language_tool_python\n",
        "    tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "    if pred_score >= 5:\n",
        "        summary = \"Excellent structure and clear arguments. Well done!\"\n",
        "    elif pred_score >= 4:\n",
        "        summary = \"Good essay overall. You can improve argument depth and cohesion.\"\n",
        "    elif pred_score >= 3:\n",
        "        summary = \"Fair effort. Focus on clearer structure and stronger evidence.\"\n",
        "    elif pred_score >= 2:\n",
        "        summary = \"Needs improvement. Clarify your position and organize ideas better.\"\n",
        "    else:\n",
        "        summary = \"Work on developing your thesis and supporting it with clear reasons.\"\n",
        "\n",
        "    feedback_points = []\n",
        "    words = word_tokenize(essay_text)\n",
        "    sentences = sent_tokenize(essay_text)\n",
        "\n",
        "    if len(words) < 150:\n",
        "        feedback_points.append(\"Essay is too short — expand your arguments.\")\n",
        "    if len(sentences) < 5:\n",
        "        feedback_points.append(\"Use more sentence variety and elaboration.\")\n",
        "    if textstat.flesch_reading_ease(essay_text) < 40:\n",
        "        feedback_points.append(\"Simplify sentence structure for better clarity.\")\n",
        "    if \"however\" not in essay_text.lower() and \"on the other hand\" not in essay_text.lower():\n",
        "        feedback_points.append(\"Use transition words to improve logical flow.\")\n",
        "\n",
        "    matches = tool.check(essay_text)\n",
        "    if len(matches) > 0:\n",
        "        feedback_points.append(f\"Grammar issues detected: {len(matches)} potential problems.\")\n",
        "\n",
        "    content_marks, matched_keywords = content_score(essay_text, content_keywords)\n",
        "    feedback_points.append(f\"Content Score: {content_marks}/4. Keywords matched: {', '.join(matched_keywords)}\")\n",
        "\n",
        "    suggestions = \" \".join(feedback_points)\n",
        "    return f\"{summary}\\n\\nSuggestions:\\n{suggestions if suggestions else 'None. Keep it up!'}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "XLwjFURe6Xe7",
        "outputId": "b2997b19-3ad0-46f6-debf-445bfcf0db39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7875ae3d44fa10fb3d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7875ae3d44fa10fb3d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# === 9. Gradio Interface ===\n",
        "def score_essay(essay):\n",
        "    try:\n",
        "        extracted_keywords = extract_keywords(essay)\n",
        "        cleaned = clean_text(essay)\n",
        "        seq = tokenizer.texts_to_sequences([cleaned])\n",
        "        padded = pad_sequences(seq, maxlen=max_len)\n",
        "        pred = model.predict(padded)\n",
        "        score = int(np.clip(np.rint(pred), 0, 6).item())\n",
        "        feedback = generate_feedback(score, essay, extracted_keywords)\n",
        "        return score, feedback\n",
        "    except Exception as e:\n",
        "        return \"Error\", f\"Exception occurred: {str(e)}\"\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=score_essay,\n",
        "    inputs=gr.Textbox(lines=20, label=\"Enter Essay\"),\n",
        "    outputs=[\n",
        "        gr.Number(label=\"Predicted Score (0–6)\"),\n",
        "        gr.Textbox(label=\"Feedback\")\n",
        "    ],\n",
        "    title=\"Automated Essay Scoring (AES) with LSTM + GloVe\",\n",
        "    description=\"Enter an argumentative essay to receive an automated score and feedback, including content-based evaluation.\",\n",
        "    examples=[\n",
        "        [\"Technology has significantly improved our lives in many ways. From faster communication...\"],\n",
        "        [\"Wales had been integrated into the Kingdom of England by the Laws in Wales Acts 1535...\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "interface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1lciDp5NU8HhteQ9bUjWCJtApGM_47fOs",
      "authorship_tag": "ABX9TyPANt/hiKH1F6E64AKPCwqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}